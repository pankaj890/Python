{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading SMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5574 \n",
      "\n",
      "0 ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "\n",
      "1 ham\tOk lar... Joking wif u oni...\n",
      "\n",
      "2 spam\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = [line for line in open('SMSSpamCollection')]\n",
    "\n",
    "print(len(messages), '\\n')\n",
    "\n",
    "for message_no, message in enumerate(messages[:3]):\n",
    "    print(message_no, message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Converting into Pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quoting - Remove those words whcich are not part of English\n",
    "# e.g. German, French etc.\n",
    "\n",
    "messages = pd.read_csv('SMSSpamCollection', sep = '\\t', quoting = csv.QUOTE_NONE, names = ['label', 'message'])\n",
    "messages.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ok lar... Joking wif u oni...'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.message.values[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Textual Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate Statistics of Messages : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4827</td>\n",
       "      <td>4518</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "      <td>653</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      message                                                               \n",
       "        count unique                                                top freq\n",
       "label                                                                       \n",
       "ham      4827   4518                             Sorry, I'll call later   30\n",
       "spam      747    653  Please call our customer service representativ...    4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group By\n",
    "\n",
    "print('Aggregate Statistics of Messages : ')\n",
    "messages.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5574</td>\n",
       "      <td>5574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4827</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                 message\n",
       "count   5574                    5574\n",
       "unique     2                    5171\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4827                      30"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.describe()      # Describe behaves according to Data-Types, we have here is textutal data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Length of Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of initial few Messages : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  Length\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111\n",
       "1   ham                      Ok lar... Joking wif u oni...      29\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
       "3   ham  U dun say so early hor... U c already then say...      49\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Length of initial few Messages : ')\n",
    "\n",
    "messages['Length'] = messages['message'].map(lambda text: len(text))\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    5574.000000\n",
      "mean       80.478292\n",
      "std        59.848302\n",
      "min         2.000000\n",
      "25%        36.000000\n",
      "50%        62.000000\n",
      "75%       122.000000\n",
      "max       910.000000\n",
      "Name: Length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(messages.Length.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"For me the love should start with attraction.i should feel that I need her every time around me.she should be the first thing which comes in my thoughts.I would start the day and end it with her.she should be there every time I dream.love will be then when my every breath has her name.my life should happen around her.my life will be named to her.I would cry for her.will give all my happiness and take all her sorrows.I will be ready to fight with anyone for her.I will be in love when I will be doing the craziest things for her.love will be when I don't have to proove anyone that my girl is the most beautiful lady on the whole planet.I will always be singing praises for her.love will be when I start up making chicken curry and end up makiing sambar.life will be the most beautiful then.will get every morning and thank god for the day because she is with me.I would like to say a lot..will tell later..\"]\n"
     ]
    }
   ],
   "source": [
    "print(list(messages.message[messages.Length > 900]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def split_into_tokens(message):\n",
    "    return TextBlob(message).words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['I', 'am', 'into', 'Machine', 'Learning', 'I', \"'d\", 'love', 'to', 'play', 'cricket'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob('I am into Machine Learning. I\\'d love to play cricket').words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Messages : \n",
      "\n",
      "0    [Go, until, jurong, point, crazy, Available, o...\n",
      "1                       [Ok, lar, Joking, wif, u, oni]\n",
      "2    [Free, entry, in, 2, a, wkly, comp, to, win, F...\n",
      "3    [U, dun, say, so, early, hor, U, c, already, t...\n",
      "4    [Nah, I, do, n't, think, he, goes, to, usf, he...\n",
      "Name: message, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('Tokenized Messages : \\n')\n",
    "print(messages.message.head().apply(split_into_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part of Speech Tags (POS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('This', 'DT'), ('is', 'VBZ'), ('for', 'IN'), ('checking', 'VBG'), ('tags', 'NNS'), ('here', 'RB')]\n"
     ]
    }
   ],
   "source": [
    "# Penn Treebank Project for Tagging of words - o/p will be (word, tag)\n",
    "# Tags = Noun, Vern and Adjective\n",
    "\n",
    "print(TextBlob('This is for checking tags here').tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nVerbs are the Words having tags [VB, VBD, VBG, VBN, VBP, VBZ]\\nAdjective are the Words having tags [JJ, JJR, JJS]\\nNouns are the Words having tags [NN, NNP, NNS]\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Verbs are the Words having tags [VB, VBD, VBG, VBN, VBP, VBZ]\n",
    "Adjective are the Words having tags [JJ, JJR, JJS]\n",
    "Nouns are the Words having tags [NN, NNP, NNS]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_lemmas(message):\n",
    "    words = TextBlob(message).words\n",
    "    lemma_form = [word.lemma for word in words]\n",
    "    return lemma_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After lemmatization, messages are : \n",
      "\n",
      "0    [Go, until, jurong, point, crazy, Available, o...\n",
      "1                       [Ok, lar, Joking, wif, u, oni]\n",
      "2    [Free, entry, in, 2, a, wkly, comp, to, win, F...\n",
      "3    [U, dun, say, so, early, hor, U, c, already, t...\n",
      "4    [Nah, I, do, n't, think, he, go, to, usf, he, ...\n",
      "Name: message, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('After lemmatization, messages are : \\n')\n",
    "print(messages.message.head().apply(split_into_lemmas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorization - CountVectorizer - Bag of Words (BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 2 0 1 0 1 1 0 1]\n",
      " [1 0 0 1 1 0 1 1 1]\n",
      " [0 1 1 1 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# General Example available on SKLEARN CountVectorizer page\n",
    "\n",
    "corpus = [\n",
    "     'This is the first document.',\n",
    "     'This document is the second document.',\n",
    "     'And this is the third one.',\n",
    "     'Is this the first document?',\n",
    "]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(vectorizer.get_feature_names())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data to Vectors - Convert the messages to a matrix of token counts: \n"
     ]
    }
   ],
   "source": [
    "# Convert SMS's to vectors\n",
    "\n",
    "print('Data to Vectors - Convert the messages to a matrix of token counts: ')\n",
    "\n",
    "# Creating object\n",
    "vectorizer = CountVectorizer(analyzer=split_into_lemmas)\n",
    "\n",
    "# Creating a sort of Model (Transformer in NLP)\n",
    "bow_transformer = vectorizer.fit(messages['message'])\n",
    "#X = vectorizer.fit(messages['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11010\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary - All unique words in all messages\n",
    "\n",
    "print(len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4189)\t2\n",
      "  (0, 4762)\t1\n",
      "  (0, 5363)\t1\n",
      "  (0, 6219)\t1\n",
      "  (0, 6243)\t1\n",
      "  (0, 7137)\t1\n",
      "  (0, 9280)\t2\n",
      "  (0, 9589)\t1\n",
      "  (0, 10054)\t1\n",
      "(1, 11010)\n",
      "\n",
      "\n",
      "Sanity Checking for words occuring 2 times: \n",
      "\n",
      "U\n",
      "say\n"
     ]
    }
   ],
   "source": [
    "# Taking single message into consideration\n",
    "\n",
    "message4 = messages.message[3]                # Fourth message in the file\n",
    "                                              # U dun say so early hor... U c already then say...\n",
    "\n",
    "# Tranform Messages into numerical form - term frequency value\n",
    "bow4 = bow_transformer.transform([message4])\n",
    "\n",
    "print(bow4)\n",
    "print(bow4.shape)\n",
    "\n",
    "\n",
    "print('\\n\\nSanity Checking for words occuring 2 times: \\n')\n",
    "\n",
    "print(vectorizer.get_feature_names()[4189])\n",
    "print(vectorizer.get_feature_names()[9280])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using BOW transformer, tranform all messages : \n",
      "\n",
      "Sparse matrix shape :  (5574, 11010)\n",
      "Number of Non-Zeros :  81623\n",
      "Sparcity : 0.13%\n"
     ]
    }
   ],
   "source": [
    "# Taking all messages into consideration\n",
    "\n",
    "print('Using BOW transformer, tranform all messages : \\n')\n",
    "\n",
    "# Tranform Messages in numerical form\n",
    "messages_bow = bow_transformer.transform(messages['message'])\n",
    "\n",
    "print('Sparse matrix shape : ', messages_bow.shape)\n",
    "print('Number of Non-Zeros : ', messages_bow.nnz)\n",
    "\n",
    "# Sparcity is the Ratio of ZEROS\n",
    "print('Sparcity : %.2f%%' % (100.0 * messages_bow.nnz / (messages_bow.shape[0] * messages_bow.shape[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorization - TF IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF fit and transform : \n"
     ]
    }
   ],
   "source": [
    "print('TF-IDF fit and transform : ')\n",
    "\n",
    "# Create object\n",
    "transformer = TfidfTransformer()\n",
    "\n",
    "# Creating a sort of Model (Transformer in NLP)\n",
    "tfidf_transformer = transformer.fit(messages_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 10054)\t0.22510385070095637\n",
      "  (0, 9589)\t0.1955442748962185\n",
      "  (0, 9280)\t0.49597495370832545\n",
      "  (0, 7137)\t0.4269339327922034\n",
      "  (0, 6243)\t0.3100112284407115\n",
      "  (0, 6219)\t0.2913528957227454\n",
      "  (0, 5363)\t0.2860779240943588\n",
      "  (0, 4762)\t0.25892595706356525\n",
      "  (0, 4189)\t0.391088549792437\n"
     ]
    }
   ],
   "source": [
    "# Taking single message into consideration\n",
    "# Fourth message\n",
    "\n",
    "# Tranform Messages into numerical form - Tf-Idf\n",
    "tfidf4 = tfidf_transformer.transform(bow4)\n",
    "\n",
    "print(tfidf4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
